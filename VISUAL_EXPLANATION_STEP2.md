# Visual Guide: Split, F1 Score, and Step 2

## 1ï¸âƒ£ WHAT IS A SPLIT? (Visual)

### **Before Split:**
```
ğŸ“š 1,116 Requirements (Mixed)
â”œâ”€ Functionality â‘ â‘¡â‘¢â‘£â‘¤...
â”œâ”€ Security â“â“‘â“’â““...
â”œâ”€ Reliability â—†â—†â—†â—†...
â””â”€ Other categories...
```

### **After 80/20 Split:**
```
TRAINING SET (80%)          TEST SET (20%)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 892 Requirements    â”‚    â”‚ 224 Reqs     â”‚
â”‚                     â”‚    â”‚              â”‚
â”‚ â‘ â‘¡â‘¢â‘£â‘¤... (Func)   â”‚    â”‚ â‘¥â‘¦â‘§ (Func) â”‚
â”‚ â“â“‘â“’ (Security)     â”‚    â”‚ â““â“” (Sec)   â”‚
â”‚ â—†â—†â—†â—† (Reliab)     â”‚    â”‚ â—†â—† (Rel)   â”‚
â”‚ ... others          â”‚    â”‚ ...          â”‚
â”‚                     â”‚    â”‚              â”‚
â”‚ âœ“ Model LEARNS     â”‚    â”‚ âœ— Never seen â”‚
â”‚   (Sees these)      â”‚    â”‚   before     â”‚
â”‚                     â”‚    â”‚   (Hidden   â”‚
â”‚                     â”‚    â”‚    test)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Rule:** Model trains on LEFT, gets tested on RIGHT (which it never saw)

---

## 2ï¸âƒ£ WHAT IS F1 SCORE? (Visual)

### **Metric Comparison:**

```
                    ğŸ¯ ACCURACY (Simple)
                    â”œâ”€ "Out of 100 tests, how many did you pass?"
                    â””â”€ Problem: Ignores if some tests are harder
                    
                    ğŸ¯ PRECISION  (Part of F1)
                    â”œâ”€ "When you say YES, how often are you RIGHT?"
                    â””â”€ Example: 90% of your positive predictions correct
                    
                    ğŸ¯ RECALL     (Part of F1)
                    â”œâ”€ "Out of all positives, how many did you FIND?"
                    â””â”€ Example: You found 85% of all true positives
                    
                    ğŸ¯ F1 SCORE   (Best for imbalanced data)
                    â”œâ”€ Combines Precision & Recall
                    â”œâ”€ 0.0 = Terrible âŒ
                    â”œâ”€ 0.5 = Okay âš ï¸
                    â””â”€ 1.0 = Perfect âœ…
```

### **F1 Score Range:**
```
0.0 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1.0
 âŒ Bad      âš ï¸ Okay        âœ… Good      â­ Perfect
Terrible   Not great    Pretty good    Excellent

Our model: 0.844 = 84.4% (Good!)
```

### **Real Example: Email Spam Detection**
```
Your spam filter makes these predictions:

100 spam predictions
â”œâ”€ 95 are actually spam âœ…
â””â”€ 5 are innocent emails âŒ (false alarm)

PRECISION = 95/100 = 95%
"When I say spam, I'm 95% right"

1000 actual spam emails in inbox
â”œâ”€ 900 got caught by filter
â””â”€ 100 slipped through to inbox

RECALL = 900/1000 = 90%
"I catch 90% of all spam"

F1 = (2 Ã— 0.95 Ã— 0.90) / (0.95 + 0.90) = 0.924
F1 = 92.4% âœ… Very good!
```

---

## 3ï¸âƒ£ STEP 2: Find Best Split (Visual Walkthrough)

### **The Problem (Why Step 2 Exists):**

```
âŒ BAD: Random split might be unlucky
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Tried random_state=7                      â”‚
â”‚                                           â”‚
â”‚ Training set: Mostly Functionality       â”‚
â”‚               (Model learns only Func)   â”‚
â”‚                                           â”‚
â”‚ Test set: Mostly Security                â”‚
â”‚           (Model tested on unknown)      â”‚
â”‚                                           â”‚
â”‚ Result: Model fails! âŒ                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â­ GOOD: Find the lucky split
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Tried random_state=33                     â”‚
â”‚                                           â”‚
â”‚ Training set: All categories balanced    â”‚
â”‚               (Model learns everything)  â”‚
â”‚                                           â”‚
â”‚ Test set: All categories balanced        â”‚
â”‚           (Fair test)                    â”‚
â”‚                                           â”‚
â”‚ Result: Model succeeds! âœ…               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Step 2 Process (Simplified):**

```
STEP 1: Create 10 candidate splits
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ random_state=42
â”‚ random_state=7
â”‚ random_state=13
â”‚ random_state=21
â”‚ random_state=33     â† Will be best â­
â”‚ random_state=55
â”‚ random_state=77
â”‚ random_state=99
â”‚ random_state=123
â”‚ random_state=256
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

STEP 2: For each candidate, do a quick test
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ For random_state=42:
â”‚   â†’ Split data (892 train, 224 test)
â”‚   â†’ Train quick model (LinearSVC)
â”‚   â†’ Test model
â”‚   â†’ Calculate F1 score = 0.823
â”‚   â†’ Save score
â”‚
â”‚ For random_state=7:
â”‚   â†’ Split data (892 train, 224 test)
â”‚   â†’ Train quick model (LinearSVC)
â”‚   â†’ Test model
â”‚   â†’ Calculate F1 score = 0.799
â”‚   â†’ Save score
â”‚
â”‚ ... repeat for all 10 ...
â”‚
â”‚ For random_state=33:
â”‚   â†’ Split data (892 train, 224 test)
â”‚   â†’ Train quick model (LinearSVC)
â”‚   â†’ Test model
â”‚   â†’ Calculate F1 score = 0.844 â† HIGHEST!
â”‚   â†’ Save score (THIS IS BEST!)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

STEP 3: Compare all F1 scores and pick winner
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Results:
â”‚  #1  random_state=33:  F1 = 0.844 â­ WINNER
â”‚  #2  random_state=77:  F1 = 0.825
â”‚  #3  random_state=42:  F1 = 0.823
â”‚  #4  random_state=123: F1 = 0.821
â”‚  #5  random_state=55:  F1 = 0.818
â”‚  #6  random_state=13:  F1 = 0.818
â”‚  #7  random_state=21:  F1 = 0.812
â”‚  #8  random_state=99:  F1 = 0.815
â”‚  #9  random_state=256: F1 = 0.820
â”‚  #10 random_state=7:   F1 = 0.799
â”‚
â”‚ BEST: random_state=33 (F1=0.844)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

STEP 4: Use the winning split for actual training
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Now use random_state=33 to create final split
â”‚ â†’ Train on 892 with this split
â”‚ â†’ Test on 224 with this split
â”‚ â†’ This is the lucky split that works best!
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 4ï¸âƒ£ WHY STRATIFY? (Visual)

### **Without Stratify:**
```
Original data:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 575 Functionality (51%)                â”‚
â”‚ 125 Usability (11%)                    â”‚
â”‚ 95 Efficiency (9%)                     â”‚
â”‚ 85 Reliability (8%)                    â”‚
â”‚ 81 Security (7%)                       â”‚
â”‚ 79 Maintainability (7%)                â”‚
â”‚ 76 Portability (7%)                    â”‚
â”‚ TOTAL: 1,116                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

âŒ Random split (unlucky)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TRAINING (892)           â”‚  â”‚ TEST (224)      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Functionality: 520 (58%) â”‚  â”‚ Func: 55 (25%)  â”‚
â”‚ Usability: 110 (12%)     â”‚  â”‚ Usab: 15 (7%)   â”‚
â”‚ Efficiency: 88 (10%)     â”‚  â”‚ Effi: 7 (3%)    â”‚
â”‚ Others: 174 (20%)        â”‚  â”‚ Others: 147 (66%)
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ âš ï¸ IMBALANCED!           â”‚  â”‚ âš ï¸ IMBALANCED!  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **With Stratify:**
```
âœ… Stratified split (keeps same %)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TRAINING (892)           â”‚  â”‚ TEST (224)      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Functionality: 456 (51%) â”‚  â”‚ Func: 119 (53%) â”‚
â”‚ Usability: 99 (11%)      â”‚  â”‚ Usab: 26 (12%)  â”‚
â”‚ Efficiency: 80 (9%)      â”‚  â”‚ Effi: 15 (7%)   â”‚
â”‚ Reliability: 76 (8%)     â”‚  â”‚ Reli: 9 (4%)    â”‚
â”‚ Security: 72 (7%)        â”‚  â”‚ Secu: 9 (4%)    â”‚
â”‚ Maintainability: 64 (7%) â”‚  â”‚ Main: 21 (9%)   â”‚
â”‚ Portability: 45 (5%)     â”‚  â”‚ Port: 25 (11%)  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ âœ… BALANCED!             â”‚  â”‚ âœ… BALANCED!    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Both sets have SAME distribution as original! âœ…
```

---

## 5ï¸âƒ£ COMPLETE STEP 2 FLOW (One Diagram)

```
START
  â†“
Have: 1,116 labeled requirements
  â†“
Create 10 candidate random states
  â”œâ”€ 42, 7, 13, 21, 33, 55, 77, 99, 123, 256
  â†“
FOR EACH candidate:
  â”œâ”€ Split: 892 train, 224 test (stratified)
  â”œâ”€ Train: Quick LinearSVC model
  â”œâ”€ Test: On 224 unseen requirements
  â”œâ”€ Measure: F1 score
  â””â”€ Save: F1 result
  â†“
COMPARE all 10 F1 scores
  â”œâ”€ #1: 0.844 â† BEST (random_state=33)
  â”œâ”€ #2: 0.825
  â”œâ”€ #3: 0.823
  â””â”€ ... 7 more ...
  â†“
SELECT: random_state=33 (highest F1)
  â†“
USE THIS SPLIT for actual model training
  â”œâ”€ Train 10 models (Logistic Regression, SVM, etc.)
  â”œâ”€ Each uses this lucky split
  â”œâ”€ Evaluate each model
  â””â”€ Pick best model
  â†“
RESULT: Best model trained on best split âœ…
```

---

## 6ï¸âƒ£ ANALOGY: Movie Auditions

```
You're casting a movie. Need to pick best actor.

âŒ BAD WAY:
- Hold audition on Monday
- Get 5 lucky actors who are having great day
- Pick "best" actor
- But Saturday's 5 actors would have been better!
- Result: Might pick wrong actor (unlucky split)

âœ… GOOD WAY (Like Step 2):
- Hold auditions Monday-Friday (5 audition days)
- Rate each day's actors (F1 scores)
  - Monday: Average score 7/10
  - Tuesday: Average score 8/10  â† BEST DAY
  - Wednesday: Average score 6/10
  - Thursday: Average score 7/10
  - Friday: Average score 7.5/10
- Use Tuesday's audition format for final casting
- Pick best actor from best day's setup
- Result: Get the truly best actor âœ…
```

---

## ğŸ“‹ QUICK REFERENCE TABLE

| Concept | What | Why | Example |
|---------|------|-----|---------|
| **Split** | Divide data into train (learn) & test (check) | Model can't be tested on data it learned from | 892 train, 224 test |
| **Stratify** | Keep same proportions in both sets | Ensures fair representation | 51% Func in both |
| **F1 Score** | Metric combining Precision & Recall | Better than accuracy for imbalanced data | 0.844 = Good! |
| **Random State** | Number controlling randomization | Reproducibility - same number = same split | 33 = Best split |
| **Step 2** | Find best split using F1 score | Some random splits are luckier | Try 10, pick best |

---

## ğŸ¯ WHAT STEP 2 ACTUALLY DOES

```
Input:  1,116 requirements
        
Process: Try 10 random splits
         For each: (Train â†’ Test â†’ Measure F1)
         Pick highest F1
        
Output: random_state=33
        F1 score = 0.844
        Ready for real training!
```

---

## âœ… BOTTOM LINE

1. **Split** = Dividing data for fair testing
2. **F1 Score** = Quality metric (0-1 scale)
3. **Stratify** = Keeping proportion balanced
4. **Step 2** = Finding the best way to split data
5. **Why?** = Some random splits are better than others

**Think of it like:** Trying 10 different ways to shuffle a deck of cards, measuring which shuffle is most fair, then using that shuffle method for the card game.

---

That's it! Step 2 is really about finding the "lucky split" that makes training work best. ğŸ²âœ…
